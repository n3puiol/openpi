{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7a1bde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e70c08cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/s5649552/conda/envs/openpi/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from openpi.training import config as _config\n",
    "import jax\n",
    "import flax.nnx as nnx\n",
    "from scripts.train import _load_weights_and_validate\n",
    "from PIL import Image\n",
    "import jax.numpy as jnp\n",
    "import openpi.transforms as _transforms\n",
    "import numpy as np\n",
    "import openpi.training.data_loader as _data_loader\n",
    "import openpi.models.tokenizer as _tokenizer\n",
    "import openpi.training.sharding as sharding\n",
    "import lerobot.common.datasets.lerobot_dataset as lerobot_dataset\n",
    "from openpi.models import model as _model\n",
    "from openpi.models.pi0_fast import Pi0FAST, make_attn_mask\n",
    "import argparse\n",
    "from plot_reward import plot_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f9fe77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(config) -> Pi0FAST:\n",
    "    rng = jax.random.key(42)  # or any seed\n",
    "    model_rng, _ = jax.random.split(rng)\n",
    "\n",
    "    model = config.model.create(model_rng)\n",
    "\n",
    "    params_shape = nnx.state(model).to_pure_dict()\n",
    "\n",
    "    loaded_params = _load_weights_and_validate(config.weight_loader, params_shape)\n",
    "\n",
    "    graphdef, state = nnx.split(model)\n",
    "    state.replace_by_pure_dict(loaded_params)\n",
    "    model = nnx.merge(graphdef, state)\n",
    "    return model\n",
    "\n",
    "def get_dataset(config):\n",
    "    data_config = config.data.create(config.assets_dirs, config.model)\n",
    "    dataset = _data_loader.create_torch_dataset(\n",
    "        data_config, config.model.action_horizon, config.model\n",
    "    )\n",
    "    transformed_dataset = _data_loader.transform_dataset(dataset, data_config)\n",
    "    return transformed_dataset\n",
    "\n",
    "def get_episode_data_index(config):\n",
    "    repo_id = config.data.repo_id\n",
    "    dataset = lerobot_dataset.LeRobotDataset(repo_id)\n",
    "    return dataset.episode_data_index\n",
    "\n",
    "\n",
    "def get_observation(dataset, index):\n",
    "    element = dataset[index]\n",
    "    batched_element = jax.tree.map(\n",
    "        lambda x: jnp.expand_dims(jnp.array(x), axis=0), element\n",
    "    )\n",
    "    observation = _model.Observation.from_dict(batched_element)\n",
    "    return observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "752c8dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some kwargs in processor config are unused and will not have any effect: min_token, scale, action_dim, time_horizon, vocab_size. \n",
      "Some kwargs in processor config are unused and will not have any effect: min_token, scale, action_dim, time_horizon, vocab_size. \n",
      "WARNING:root:\n",
      "The dataset you requested (physical-intelligence/libero) is in 2.0 format.\n",
      "While current version of LeRobot is backward-compatible with it, the version of your dataset still uses global\n",
      "stats instead of per-episode stats. Update your dataset stats to the new format using this command:\n",
      "```\n",
      "python lerobot/common/datasets/v21/convert_dataset_v20_to_v21.py --repo-id=physical-intelligence/libero\n",
      "```\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n",
      "WARNING:root:\n",
      "The dataset you requested (physical-intelligence/libero) is in 2.0 format.\n",
      "While current version of LeRobot is backward-compatible with it, the version of your dataset still uses global\n",
      "stats instead of per-episode stats. Update your dataset stats to the new format using this command:\n",
      "```\n",
      "python lerobot/common/datasets/v21/convert_dataset_v20_to_v21.py --repo-id=physical-intelligence/libero\n",
      "```\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n",
      "WARNING:root:\n",
      "The dataset you requested (physical-intelligence/libero) is in 2.0 format.\n",
      "While current version of LeRobot is backward-compatible with it, the version of your dataset still uses global\n",
      "stats instead of per-episode stats. Update your dataset stats to the new format using this command:\n",
      "```\n",
      "python lerobot/common/datasets/v21/convert_dataset_v20_to_v21.py --repo-id=physical-intelligence/libero\n",
      "```\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = _config.get_config(\"pi0_fast_libero\")\n",
    "dataset = get_dataset(config)\n",
    "model = load_model(config)\n",
    "episode_data_index = get_episode_data_index(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ce0198c",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_episodes = episode_data_index[\"to\"].cpu().numpy()\n",
    "index = int(end_episodes[0]) - 1 \n",
    "observation = get_observation(dataset, index)\n",
    "\n",
    "rng = jax.random.key(0)\n",
    "train = False\n",
    "\n",
    "preprocess_rng, noise_rng, time_rng = jax.random.split(rng, 3)\n",
    "observation = _model.preprocess_observation(preprocess_rng, observation, train=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e1175cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_embeddings, input_mask, ar_mask = model.embed_inputs(observation)\n",
    "attn_mask = make_attn_mask(input_mask, ar_mask)\n",
    "fused_sequence_embeddings, _, _ = model.PaliGemma.llm(\n",
    "    embedded_prefix=input_token_embeddings,\n",
    "    mask=attn_mask,\n",
    "    return_prelogits=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2b93071",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_expanded = jnp.expand_dims(input_mask, axis=-1)\n",
    "summed_embeddings = jnp.sum(fused_sequence_embeddings * mask_expanded, axis=1)\n",
    "num_valid_tokens = jnp.sum(input_mask, axis=1, keepdims=True)\n",
    "pooled_fused_embedding = summed_embeddings / jnp.maximum(num_valid_tokens, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0708628e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2048)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fused_sequence_embeddings[:, -1, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a5c10a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openpi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
